{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Instal libraries","metadata":{}},{"cell_type":"code","source":"# block for pip\n%pip -q install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-24T11:25:00.992354Z","iopub.execute_input":"2024-09-24T11:25:00.992644Z","iopub.status.idle":"2024-09-24T11:25:15.496895Z","shell.execute_reply.started":"2024-09-24T11:25:00.992605Z","shell.execute_reply":"2024-09-24T11:25:15.495714Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Importint libraries","metadata":{}},{"cell_type":"code","source":"# block for import\nfrom transformers import AutoTokenizer, TrainingArguments, AutoModelForQuestionAnswering, Trainer\nfrom datasets import load_dataset\nfrom tqdm.auto import tqdm\nimport collections\nimport numpy as np\nimport evaluate","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:20:12.742326Z","iopub.execute_input":"2024-09-24T13:20:12.742918Z","iopub.status.idle":"2024-09-24T13:20:12.749184Z","shell.execute_reply.started":"2024-09-24T13:20:12.742878Z","shell.execute_reply":"2024-09-24T13:20:12.748027Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Setting dataset and model names\ndataset = \"kuznetsoffandrey/sberquad\"\nmodel_checkpoint = \"bert-base-multilingual-cased\"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:34.422943Z","iopub.execute_input":"2024-09-24T11:25:34.423583Z","iopub.status.idle":"2024-09-24T11:25:34.427646Z","shell.execute_reply.started":"2024-09-24T11:25:34.423546Z","shell.execute_reply":"2024-09-24T11:25:34.426646Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset load and preparation","metadata":{}},{"cell_type":"code","source":"raw_dataset = load_dataset(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:34.430376Z","iopub.execute_input":"2024-09-24T11:25:34.430780Z","iopub.status.idle":"2024-09-24T11:25:38.922324Z","shell.execute_reply.started":"2024-09-24T11:25:34.430735Z","shell.execute_reply":"2024-09-24T11:25:38.921581Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec950fb3a7bb4b53acf116c5674ac07b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"423036593d1b41169082023317fb588f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.43M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c23f4f2cf49647188ed3f317381f28a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15a66de9e1ad4279b1aaee7bc313fc2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/45328 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89c1e365c02f4bb2b729032bd5e53af4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5036 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d81770d471449aa677186747626573"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/23936 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afa05896542344028815f2619658df31"}},"metadata":{}}]},{"cell_type":"raw","source":"raw_dataset","metadata":{}},{"cell_type":"code","source":"print(\"Context: \", raw_dataset[\"train\"][0][\"context\"])\nprint(\"Question: \", raw_dataset[\"train\"][0][\"question\"])\nprint(\"Answer: \", raw_dataset[\"train\"][0][\"answers\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:38.923498Z","iopub.execute_input":"2024-09-24T11:25:38.923892Z","iopub.status.idle":"2024-09-24T11:25:38.935300Z","shell.execute_reply.started":"2024-09-24T11:25:38.923848Z","shell.execute_reply":"2024-09-24T11:25:38.934266Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Context:  Ð’ Ð¿Ñ€Ð¾Ñ‚ÐµÑ€Ð¾Ð·Ð¾Ð¹ÑÐºÐ¸Ñ… Ð¾Ñ‚Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÑ… Ð¾Ñ€Ð³Ð°Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‚ÑÑ Ð½Ð°Ð¼Ð½Ð¾Ð³Ð¾ Ñ‡Ð°Ñ‰Ðµ, Ñ‡ÐµÐ¼ Ð² Ð°Ñ€Ñ…ÐµÐ¹ÑÐºÐ¸Ñ…. ÐžÐ½Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¸Ð·Ð²ÐµÑÑ‚ÐºÐ¾Ð²Ñ‹Ð¼Ð¸ Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ð¸ÑÐ¼Ð¸ ÑÐ¸Ð½Ðµ-Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ñ… Ð²Ð¾Ð´Ð¾Ñ€Ð¾ÑÐ»ÐµÐ¹, Ñ…Ð¾Ð´Ð°Ð¼Ð¸ Ñ‡ÐµÑ€Ð²ÐµÐ¹, Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ°Ð¼Ð¸ ÐºÐ¸ÑˆÐµÑ‡Ð½Ð¾Ð¿Ð¾Ð»Ð¾ÑÑ‚Ð½Ñ‹Ñ…. ÐšÑ€Ð¾Ð¼Ðµ Ð¸Ð·Ð²ÐµÑÑ‚ÐºÐ¾Ð²Ñ‹Ñ… Ð²Ð¾Ð´Ð¾Ñ€Ð¾ÑÐ»ÐµÐ¹, Ðº Ñ‡Ð¸ÑÐ»Ñƒ Ð´Ñ€ÐµÐ²Ð½ÐµÐ¹ÑˆÐ¸Ñ… Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¾Ð² Ð¾Ñ‚Ð½Ð¾ÑÑÑ‚ÑÑ ÑÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ Ð³Ñ€Ð°Ñ„Ð¸Ñ‚Ð¾-ÑƒÐ³Ð»Ð¸ÑÑ‚Ð¾Ð³Ð¾ Ð²ÐµÑ‰ÐµÑÑ‚Ð²Ð°, Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð²ÑˆÐµÐ³Ð¾ÑÑ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ Ñ€Ð°Ð·Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Corycium enigmaticum. Ð’ ÐºÑ€ÐµÐ¼Ð½Ð¸ÑÑ‚Ñ‹Ñ… ÑÐ»Ð°Ð½Ñ†Ð°Ñ… Ð¶ÐµÐ»ÐµÐ·Ð¾Ñ€ÑƒÐ´Ð½Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ ÐšÐ°Ð½Ð°Ð´Ñ‹ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð½Ð¸Ñ‚ÐµÐ²Ð¸Ð´Ð½Ñ‹Ðµ Ð²Ð¾Ð´Ð¾Ñ€Ð¾ÑÐ»Ð¸, Ð³Ñ€Ð¸Ð±Ð½Ñ‹Ðµ Ð½Ð¸Ñ‚Ð¸ Ð¸ Ñ„Ð¾Ñ€Ð¼Ñ‹, Ð±Ð»Ð¸Ð·ÐºÐ¸Ðµ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¼ ÐºÐ¾ÐºÐºÐ¾Ð»Ð¸Ñ‚Ð¾Ñ„Ð¾Ñ€Ð¸Ð´Ð°Ð¼. Ð’ Ð¶ÐµÐ»ÐµÐ·Ð¸ÑÑ‚Ñ‹Ñ… ÐºÐ²Ð°Ñ€Ñ†Ð¸Ñ‚Ð°Ñ… Ð¡ÐµÐ²ÐµÑ€Ð½Ð¾Ð¹ ÐÐ¼ÐµÑ€Ð¸ÐºÐ¸ Ð¸ Ð¡Ð¸Ð±Ð¸Ñ€Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¶ÐµÐ»ÐµÐ·Ð¸ÑÑ‚Ñ‹Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹ Ð¶Ð¸Ð·Ð½ÐµÐ´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð±Ð°ÐºÑ‚ÐµÑ€Ð¸Ð¹.\nQuestion:  Ñ‡ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸?\nAnswer:  {'text': ['Ð¸Ð·Ð²ÐµÑÑ‚ÐºÐ¾Ð²Ñ‹Ð¼Ð¸ Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ð¸ÑÐ¼Ð¸ ÑÐ¸Ð½Ðµ-Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ñ… Ð²Ð¾Ð´Ð¾Ñ€Ð¾ÑÐ»ÐµÐ¹'], 'answer_start': [109]}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading tokenier\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:38.936459Z","iopub.execute_input":"2024-09-24T11:25:38.936843Z","iopub.status.idle":"2024-09-24T11:25:40.898476Z","shell.execute_reply.started":"2024-09-24T11:25:38.936800Z","shell.execute_reply":"2024-09-24T11:25:40.897416Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dd49c90904545afaa5af9c19dc5cdc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8817a46cf04434a4df2b9ec655bcf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"197e5c2a9a9d495f8008109e9f34a336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54f1e034e1604f3bba27230d58d3f014"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.is_fast","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:40.899637Z","iopub.execute_input":"2024-09-24T11:25:40.899991Z","iopub.status.idle":"2024-09-24T11:25:40.907191Z","shell.execute_reply.started":"2024-09-24T11:25:40.899958Z","shell.execute_reply":"2024-09-24T11:25:40.906334Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Checking that tokenizer set context and question in right tokens ([CLS] and [SEP])\ncontext = raw_dataset[\"train\"][0][\"context\"]\nquestion = raw_dataset[\"train\"][0][\"question\"]\n\ninputs = tokenizer(question, context)\ntokenizer.decode(inputs[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:40.908416Z","iopub.execute_input":"2024-09-24T11:25:40.908725Z","iopub.status.idle":"2024-09-24T11:25:40.924856Z","shell.execute_reply.started":"2024-09-24T11:25:40.908690Z","shell.execute_reply":"2024-09-24T11:25:40.924043Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'[CLS] Ñ‡ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸? [SEP] Ð’ Ð¿Ñ€Ð¾Ñ‚ÐµÑ€Ð¾Ð·Ð¾Ð¹ÑÐºÐ¸Ñ… Ð¾Ñ‚Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÑ… Ð¾Ñ€Ð³Ð°Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‚ÑÑ Ð½Ð°Ð¼Ð½Ð¾Ð³Ð¾ Ñ‡Ð°Ñ‰Ðµ, Ñ‡ÐµÐ¼ Ð² Ð°Ñ€Ñ…ÐµÐ¹ÑÐºÐ¸Ñ…. ÐžÐ½Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¸Ð·Ð²ÐµÑÑ‚ÐºÐ¾Ð²Ñ‹Ð¼Ð¸ Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ð¸ÑÐ¼Ð¸ ÑÐ¸Ð½Ðµ - Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ñ… Ð²Ð¾Ð´Ð¾Ñ€Ð¾ÑÐ»ÐµÐ¹, Ñ…Ð¾Ð´Ð°Ð¼Ð¸ Ñ‡ÐµÑ€Ð²ÐµÐ¹, Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ°Ð¼Ð¸ ÐºÐ¸ÑˆÐµÑ‡Ð½Ð¾Ð¿Ð¾Ð»Ð¾ÑÑ‚Ð½Ñ‹Ñ…. ÐšÑ€Ð¾Ð¼Ðµ Ð¸Ð·Ð²ÐµÑÑ‚ÐºÐ¾Ð²Ñ‹Ñ… Ð²Ð¾Ð´Ð¾Ñ€Ð¾ÑÐ»ÐµÐ¹, Ðº Ñ‡Ð¸ÑÐ»Ñƒ Ð´Ñ€ÐµÐ²Ð½ÐµÐ¹ÑˆÐ¸Ñ… Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¾Ð² Ð¾Ñ‚Ð½Ð¾ÑÑÑ‚ÑÑ ÑÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ Ð³Ñ€Ð°Ñ„Ð¸Ñ‚Ð¾ - ÑƒÐ³Ð»Ð¸ÑÑ‚Ð¾Ð³Ð¾ Ð²ÐµÑ‰ÐµÑÑ‚Ð²Ð°, Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð²ÑˆÐµÐ³Ð¾ÑÑ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ Ñ€Ð°Ð·Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Corycium enigmaticum. Ð’ ÐºÑ€ÐµÐ¼Ð½Ð¸ÑÑ‚Ñ‹Ñ… ÑÐ»Ð°Ð½Ñ†Ð°Ñ… Ð¶ÐµÐ»ÐµÐ·Ð¾Ñ€ÑƒÐ´Ð½Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ ÐšÐ°Ð½Ð°Ð´Ñ‹ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð½Ð¸Ñ‚ÐµÐ²Ð¸Ð´Ð½Ñ‹Ðµ Ð²Ð¾Ð´Ð¾Ñ€Ð¾ÑÐ»Ð¸, Ð³Ñ€Ð¸Ð±Ð½Ñ‹Ðµ Ð½Ð¸Ñ‚Ð¸ Ð¸ Ñ„Ð¾Ñ€Ð¼Ñ‹, Ð±Ð»Ð¸Ð·ÐºÐ¸Ðµ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¼ ÐºÐ¾ÐºÐºÐ¾Ð»Ð¸Ñ‚Ð¾Ñ„Ð¾Ñ€Ð¸Ð´Ð°Ð¼. Ð’ Ð¶ÐµÐ»ÐµÐ·Ð¸ÑÑ‚Ñ‹Ñ… ÐºÐ²Ð°Ñ€Ñ†Ð¸Ñ‚Ð°Ñ… Ð¡ÐµÐ²ÐµÑ€Ð½Ð¾Ð¹ ÐÐ¼ÐµÑ€Ð¸ÐºÐ¸ Ð¸ Ð¡Ð¸Ð±Ð¸Ñ€Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¶ÐµÐ»ÐµÐ·Ð¸ÑÑ‚Ñ‹Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹ Ð¶Ð¸Ð·Ð½ÐµÐ´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð±Ð°ÐºÑ‚ÐµÑ€Ð¸Ð¹. [SEP]'"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_training_examples(examples, max_length=384, stride=128):\n    questions = [q.strip() for q in examples[\"question\"]] # clear spaces\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = answers[sample_idx]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find start and end of context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If answer not fully in context, then set labels to (0, 0)\n        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Else add start and end position of answer\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:40.941833Z","iopub.execute_input":"2024-09-24T11:25:40.942306Z","iopub.status.idle":"2024-09-24T11:25:40.953198Z","shell.execute_reply.started":"2024-09-24T11:25:40.942275Z","shell.execute_reply":"2024-09-24T11:25:40.952187Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def preprocess_validation_examples(examples, max_length=384, stride=128):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n        offset = inputs[\"offset_mapping\"][i]\n        inputs[\"offset_mapping\"][i] = [\n            ofst if sequence_ids[idx] == 1 else None for idx, ofst in enumerate(offset)\n        ]\n\n    inputs[\"example_id\"] = example_ids\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:40.954287Z","iopub.execute_input":"2024-09-24T11:25:40.954567Z","iopub.status.idle":"2024-09-24T11:25:40.965183Z","shell.execute_reply.started":"2024-09-24T11:25:40.954533Z","shell.execute_reply":"2024-09-24T11:25:40.964424Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = raw_dataset[\"train\"].map(\n    preprocess_training_examples,\n    batched=True,\n    remove_columns=raw_dataset[\"train\"].column_names,\n)\nlen(raw_dataset[\"train\"]), len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:25:40.966131Z","iopub.execute_input":"2024-09-24T11:25:40.966429Z","iopub.status.idle":"2024-09-24T11:26:14.066437Z","shell.execute_reply.started":"2024-09-24T11:25:40.966397Z","shell.execute_reply":"2024-09-24T11:26:14.065548Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45328 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07742371e7c346ad9b9069a66e5688a1"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(45328, 47782)"},"metadata":{}}]},{"cell_type":"code","source":"validation_dataset = raw_dataset[\"validation\"].map(\n    preprocess_validation_examples,\n    batched=True,\n    remove_columns=raw_dataset[\"validation\"].column_names,\n)\nlen(raw_dataset[\"validation\"]), len(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:26:14.067834Z","iopub.execute_input":"2024-09-24T11:26:14.068163Z","iopub.status.idle":"2024-09-24T11:26:19.137876Z","shell.execute_reply.started":"2024-09-24T11:26:14.068129Z","shell.execute_reply":"2024-09-24T11:26:19.136896Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5036 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51033e0fcba14467a926573b3a81d79d"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(5036, 5316)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model tuning","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"huggingface\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:26:19.154721Z","iopub.execute_input":"2024-09-24T11:26:19.155145Z","iopub.status.idle":"2024-09-24T11:26:19.587286Z","shell.execute_reply.started":"2024-09-24T11:26:19.155097Z","shell.execute_reply":"2024-09-24T11:26:19.586339Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:26:19.588511Z","iopub.execute_input":"2024-09-24T11:26:19.588902Z","iopub.status.idle":"2024-09-24T11:26:19.702644Z","shell.execute_reply.started":"2024-09-24T11:26:19.588857Z","shell.execute_reply":"2024-09-24T11:26:19.701728Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:29:16.546912Z","iopub.execute_input":"2024-09-24T11:29:16.547289Z","iopub.status.idle":"2024-09-24T11:29:19.511365Z","shell.execute_reply.started":"2024-09-24T11:29:16.547253Z","shell.execute_reply":"2024-09-24T11:29:19.510435Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eac8de3600c407dafb7251b264d14be"}},"metadata":{}},{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nSome weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"args = TrainingArguments(\n    \"bert-finetuned-sbersquad\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:29:42.529502Z","iopub.execute_input":"2024-09-24T11:29:42.530235Z","iopub.status.idle":"2024-09-24T11:29:42.607613Z","shell.execute_reply.started":"2024-09-24T11:29:42.530178Z","shell.execute_reply":"2024-09-24T11:29:42.606558Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:29:42.609220Z","iopub.execute_input":"2024-09-24T11:29:42.609545Z","iopub.status.idle":"2024-09-24T13:12:47.202441Z","shell.execute_reply.started":"2024-09-24T11:29:42.609512Z","shell.execute_reply":"2024-09-24T13:12:47.201308Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240924_113030-s0x1zpgp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aboba_team/huggingface/runs/s0x1zpgp' target=\"_blank\">bert-finetuned-sbersquad</a></strong> to <a href='https://wandb.ai/aboba_team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aboba_team/huggingface' target=\"_blank\">https://wandb.ai/aboba_team/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aboba_team/huggingface/runs/s0x1zpgp' target=\"_blank\">https://wandb.ai/aboba_team/huggingface/runs/s0x1zpgp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='17919' max='17919' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [17919/17919 1:41:36, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.765000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.125600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.905300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.831700</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.798400</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.822500</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.706200</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.756200</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.716300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.612500</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.702400</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.620400</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.398600</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.400900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.391700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.347300</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.337700</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.372400</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.350300</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.385100</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>1.357000</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>1.338600</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>1.321500</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.357100</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>1.085100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>1.105700</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>1.059100</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>1.069000</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>1.086200</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>1.056800</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>1.083300</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>1.099300</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>1.056900</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>1.045800</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>1.039700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=17919, training_loss=1.4333324167330461, metrics={'train_runtime': 6160.2732, 'train_samples_per_second': 23.269, 'train_steps_per_second': 2.909, 'total_flos': 2.809188366830899e+16, 'train_loss': 1.4333324167330461, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:13:27.907099Z","iopub.execute_input":"2024-09-24T13:13:27.907887Z","iopub.status.idle":"2024-09-24T13:13:37.527741Z","shell.execute_reply.started":"2024-09-24T13:13:27.907847Z","shell.execute_reply":"2024-09-24T13:13:37.526533Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1727177384.c38230d8d4c4.36.0:   0%|          | 0.00/12.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ceb68d073ca40debf3b23738e976b16"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Megnis/bert-finetuned-sbersquad/commit/6ca047546af3ce5f5cb54d1a18e19bad5f85cc69', commit_message='End of training', commit_description='', oid='6ca047546af3ce5f5cb54d1a18e19bad5f85cc69', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}